from flask import Flask, request, jsonify
from flask_cors import CORS
import joblib
import json
import re
import string
import pandas as pd
import numpy as np
import os
from datetime import datetime
import logging


# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Permite requisi√ß√µes de qualquer origem (ajuste conforme necess√°rio)

# Vari√°veis globais para o modelo e informa√ß√µes
model = None
model_info = None

def load_model():
    """Carrega o modelo treinado e suas informa√ß√µes"""
    global model, model_info
    
    try:
        # Carregar o modelo
        if os.path.exists('hate_speech_classifier_model.pkl'):
            model = joblib.load('hate_speech_classifier_model.pkl')
            logger.info("‚úÖ Modelo carregado com sucesso!")
        else:
            raise FileNotFoundError("Arquivo do modelo n√£o encontrado!")
        
        # Carregar informa√ß√µes do modelo
        if os.path.exists('model_info.json'):
            with open('model_info.json', 'r') as f:
                model_info = json.load(f)
            logger.info("‚úÖ Informa√ß√µes do modelo carregadas com sucesso!")
        else:
            logger.warning("‚ö†Ô∏è Arquivo de informa√ß√µes do modelo n√£o encontrado!")
            model_info = {}
            
    except Exception as e:
        logger.error(f"‚ùå Erro ao carregar o modelo: {e}")
        raise e

def preprocess_text(text):
    """
    Fun√ß√£o para pr√©-processar texto (mesma do notebook):
    - Converte para min√∫sculas
    - Remove pontua√ß√£o
    - Remove n√∫meros
    - Remove espa√ßos extras
    """
    if pd.isna(text) or text is None:
        return ""
    
    # Converter para string e min√∫sculas
    text = str(text).lower()
    
    # Remover pontua√ß√£o
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Remover n√∫meros
    text = re.sub(r'\d+', '', text)
    
    # Remover espa√ßos extras
    text = ' '.join(text.split())
    
    return text

def predict_hate_speech(comment, model):
    """
    Fun√ß√£o para predizer se um coment√°rio √© discurso de √≥dio
    Compat√≠vel com LinearSVC (sem predict_proba)
    """
    try:
        # Pr√©-processar o coment√°rio
        processed_comment = preprocess_text(comment)
        
        if not processed_comment.strip():
            return "Coment√°rio inv√°lido", 0.0, "error"
        
        # Fazer predi√ß√£o
        prediction = model.predict([processed_comment])[0]
        
        # Tentar obter confian√ßa
        confidence = 0.0
        confidence_method = "none"
        
        try:
            # Tenta usar predict_proba (para modelos como SVC, Naive Bayes, etc.)
            probability = model.predict_proba([processed_comment])[0]
            confidence = max(probability) * 100
            confidence_method = "probability"
        except AttributeError:
            try:
                # Para LinearSVC e outros que n√£o t√™m predict_proba
                decision = model.decision_function([processed_comment])[0]
                # Normaliza usando fun√ß√£o sigmoide para [0, 1]
                confidence = 100 * (1 / (1 + np.exp(-abs(decision))))
                confidence_method = "decision_function"
            except:
                # Se nenhum m√©todo funcionar, usa confian√ßa padr√£o
                confidence = 50.0
                confidence_method = "default"
        
        # Interpretar resultado
        result = "N√£o √© discurso de √≥dio" if prediction == 1 else "√â discurso de √≥dio"
        
        return result, confidence, confidence_method
        
    except Exception as e:
        logger.error(f"Erro na predi√ß√£o: {e}")
        return "Erro na predi√ß√£o", 0.0, "error"

@app.route('/', methods=['GET'])
def home():
    """Endpoint de status da API"""
    return jsonify({
        'status': 'API funcionando!',
        'model_loaded': model is not None,
        'model_info': model_info if model_info else {},
        'endpoints': {
            'predict': '/predict (POST)',
            'health': '/health (GET)',
            'model_info': '/model-info (GET)'
        }
    })

@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint de health check"""
    return jsonify({
        'status': 'healthy',
        'model_loaded': model is not None,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def get_model_info():
    """Endpoint para obter informa√ß√µes do modelo"""
    if model_info:
        return jsonify(model_info)
    else:
        return jsonify({'error': 'Informa√ß√µes do modelo n√£o dispon√≠veis'}), 404

@app.route('/predict', methods=['POST'])
def predict():
    """Endpoint principal para classifica√ß√£o de coment√°rios"""
    try:
        # Verificar se o modelo est√° carregado
        if model is None:
            return jsonify({
                'error': 'Modelo n√£o carregado',
                'message': 'O modelo de ML n√£o foi carregado corretamente'
            }), 500
        
        # Obter dados da requisi√ß√£o
        data = request.get_json()
        
        if not data:
            return jsonify({
                'error': 'Dados inv√°lidos',
                'message': 'Requisi√ß√£o deve conter JSON v√°lido'
            }), 400
        
        if 'comment' not in data:
            return jsonify({
                'error': 'Campo obrigat√≥rio ausente',
                'message': 'Campo "comment" √© obrigat√≥rio'
            }), 400
        
        comment = data['comment']
        
        if not comment or not isinstance(comment, str):
            return jsonify({
                'error': 'Coment√°rio inv√°lido',
                'message': 'Campo "comment" deve ser uma string n√£o vazia'
            }), 400
        
        # Fazer a predi√ß√£o
        result, confidence, confidence_method = predict_hate_speech(comment, model)
        
        if confidence_method == "error":
            return jsonify({
                'error': 'Erro na predi√ß√£o',
                'message': result
            }), 500
        
        # Preparar resposta
        response = {
            'comment': comment,
            'prediction': result,
            'is_hate_speech': result == "√â discurso de √≥dio",
            'confidence': round(confidence, 2),
            'confidence_method': confidence_method,
            'processed_comment': preprocess_text(comment),
            'timestamp': datetime.now().isoformat()
        }
        
        # Log da predi√ß√£o
        logger.info(f"Predi√ß√£o realizada: {result} (confian√ßa: {confidence:.2f}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"Erro no endpoint /predict: {e}")
        return jsonify({
            'error': 'Erro interno do servidor',
            'message': str(e)
        }), 500

@app.route('/predict/batch', methods=['POST'])
def predict_batch():
    """Endpoint para classifica√ß√£o em lote de m√∫ltiplos coment√°rios"""
    try:
        if model is None:
            return jsonify({
                'error': 'Modelo n√£o carregado',
                'message': 'O modelo de ML n√£o foi carregado corretamente'
            }), 500
        
        data = request.get_json()
        
        if not data or 'comments' not in data:
            return jsonify({
                'error': 'Campo obrigat√≥rio ausente',
                'message': 'Campo "comments" √© obrigat√≥rio'
            }), 400
        
        comments = data['comments']
        
        if not isinstance(comments, list):
            return jsonify({
                'error': 'Formato inv√°lido',
                'message': 'Campo "comments" deve ser uma lista'
            }), 400
        
        if len(comments) > 100:  # Limite de seguran√ßa
            return jsonify({
                'error': 'Muitos coment√°rios',
                'message': 'M√°ximo de 100 coment√°rios por requisi√ß√£o'
            }), 400
        
        results = []
        
        for i, comment in enumerate(comments):
            if not comment or not isinstance(comment, str):
                results.append({
                    'index': i,
                    'comment': comment,
                    'error': 'Coment√°rio inv√°lido'
                })
                continue
            
            result, confidence, confidence_method = predict_hate_speech(comment, model)
            
            results.append({
                'index': i,
                'comment': comment,
                'prediction': result,
                'is_hate_speech': result == "√â discurso de √≥dio",
                'confidence': round(confidence, 2),
                'confidence_method': confidence_method
            })
        
        return jsonify({
            'results': results,
            'total_processed': len(results),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Erro no endpoint /predict/batch: {e}")
        return jsonify({
            'error': 'Erro interno do servidor',
            'message': str(e)
        }), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'Endpoint n√£o encontrado',
        'message': 'Verifique a URL e o m√©todo HTTP'
    }), 404

@app.errorhandler(405)
def method_not_allowed(error):
    return jsonify({
        'error': 'M√©todo n√£o permitido',
        'message': 'Verifique o m√©todo HTTP da requisi√ß√£o'
    }), 405

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'error': 'Erro interno do servidor',
        'message': 'Ocorreu um erro inesperado'
    }), 500

if __name__ == '__main__':
    try:
        # Carregar o modelo na inicializa√ß√£o
        load_model()
        
        # Iniciar o servidor
        print("üöÄ Iniciando servidor Flask...")
        print("üìä API de Classifica√ß√£o de Discurso de √ìdio")
        print("üîó Endpoints dispon√≠veis:")
        print("   GET  / - Status da API")
        print("   GET  /health - Health check")
        print("   GET  /model-info - Informa√ß√µes do modelo")
        print("   POST /predict - Classificar um coment√°rio")
        print("   POST /predict/batch - Classificar m√∫ltiplos coment√°rios")
        
        app.run(host='0.0.0.0', port=5000)
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao iniciar o servidor: {e}")
        print("Certifique-se de que os arquivos do modelo est√£o no diret√≥rio correto!")